from fastapi import FastAPI, Request, HTTPException
from pydantic import BaseModel
import requests
from pinecone import Pinecone, ServerlessSpec
from groq import Groq
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os
from dotenv import load_dotenv

from models import IngestPayload, QuestionPayload, DeletePayload, ChatCompletionPayload

# Load environment variables
load_dotenv()
app = FastAPI()

# Pinecone init
pc = Pinecone(
    api_key=os.getenv("PINECONE_API_KEY")
)

index_name = os.getenv("PINECONE_INDEX_NAME")

# Groq init
client = Groq(
    api_key=os.environ.get("GROQ_API_KEY"),
)

# Define the text splitter
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,
    chunk_overlap=50,
    separators=["\n\n", "\n", ".", " ", ""]
)

# Check if the index exists, if not create it
if not pc.has_index(index_name):
    pc.create_index_for_model(
        name=index_name,
        cloud="aws",
        region="us-east-1",
        embed={
            "model":"llama-text-embed-v2",
            "field_map":{"text": "chunk_text"}
        }
    )

# Connect to the index
index = pc.Index(index_name)


# Define endpoints
@app.get("/")
def hello_world():
    return {"message": "Hello World!"}

@app.head("/v1/keep-alive")
def health_check():
        return {"status": "healthy"}

@app.post("/v1/ingest")
def ingest(payload: IngestPayload):
        
        chunks = text_splitter.split_text(payload.document)

        records = [
            {
                "id": f"{payload.documentId}-{i}",
                "text": chunk,
                'documentId': payload.documentId,
                'title': payload.title,
            } for i, chunk in enumerate(chunks)
        ]


        # index.upsert_records(payload.userId, records)

        # return {"status": "done"}
        # Batch size of 90 (below Pinecone's limit of 96)
        batch_size = 90
    
        # Split records into batches and upsert
        for i in range(0, len(records), batch_size):
            batch = records[i:i + batch_size]
            index.upsert_records(payload.userId, batch)

        return {"status": "done", "chunks_processed": len(records)}

@app.post("/v1/question")
def question(payload: QuestionPayload):
    # Define the query

    # Search the dense index
    results = index.search(
        namespace=payload.userId,
        query={
            "top_k": 15,
            "inputs": {
                'text': payload.query
            }
        }
    )

    # Print the results
    for hit in results['result']['hits']:
            print(f"id: {hit['_id']:<5} | documentId: {hit['fields']['documentId']} | title: {hit['fields']['title']} | score: {round(hit['_score'], 2):<5} | text: {hit['fields']['text']:<50}")
            

    chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": (
                "### ðŸ“˜ YÃªu cáº§u:\n"
                f"Tráº£ lá»i cÃ¢u há»i sau báº±ng cÃ¡ch dá»±a trÃªn cÃ¡c Ä‘oáº¡n vÄƒn bÃªn dÆ°á»›i. "
                "Náº¿u thÃ´ng tin khÃ´ng Ä‘á»§, hÃ£y tráº£ lá»i dá»±a trÃªn kiáº¿n thá»©c cá»§a báº¡n vÃ  ghi rÃµ Ä‘iá»u Ä‘Ã³.\n\n"
                f"**CÃ¢u há»i:** {payload.query}\n\n"
                "### ðŸ“š Äoáº¡n vÄƒn tham kháº£o:\n"
                # + "\n---\n".join([hit['fields']['text'] for hit in results['result']['hits']]) +
                # "\n\n"
                + "\n---\n".join([
                     f"**Äoáº¡n vÄƒn {i+1} (Document title: {hit['fields']['title']}):**\n"
                     f"{hit['fields']['text']}\n"
                     for i, hit in enumerate(results['result']['hits'])
                     ]) +
                "### âœï¸ Ghi chÃº khi tráº£ lá»i:\n"
                "- TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i báº±ng [Markdown] Ä‘á»ƒ há»‡ thá»‘ng `react-markdown` cÃ³ thá»ƒ hiá»ƒn thá»‹ tá»‘t.\n"
                "- Äáº£m báº£o má»—i thÃ´ng tin Ä‘Æ°á»£c trÃ­ch dáº«n Ä‘á»u cÃ³ tham chiáº¿u Ä‘áº¿n **Document title** tÆ°Æ¡ng á»©ng (vÃ­ dá»¥: `[TÃ i liá»‡u LLM]`m chá»‰ cáº§n tÃªn tÃ i liá»‡u, khÃ´ng cáº§n ghi Document title).\n"
                "- ThÃªm emoji phÃ¹ há»£p Ä‘á»ƒ lÃ m ná»•i báº­t ná»™i dung chÃ­nh ðŸ§ ðŸ“ŒðŸ’¡.\n"
                "- Náº¿u cÃ¢u tráº£ lá»i khÃ´ng thá»ƒ rÃºt ra tá»« Ä‘oáº¡n vÄƒn, hÃ£y báº¯t Ä‘áº§u báº±ng cÃ¢u: `âš ï¸ KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin trong Ä‘oáº¡n vÄƒn, cÃ¢u tráº£ lá»i Ä‘Æ°á»£c táº¡o tá»« kiáº¿n thá»©c ná»n.`"
            )
        }
    ],
    model="deepseek-r1-distill-llama-70b",
    )

    response_dict = chat_completion.model_dump()
    response_dict["choices"][0]["message"]["documents"] = [
        {
            "id": hit["_id"],
            "text": hit["fields"]["text"],
            "documentId": hit["fields"]["documentId"],
            "score": hit["_score"]
        } for hit in results['result']['hits']
    ]
    return response_dict

@app.post("/v1/delete-document")
def delete_document(payload: DeletePayload):

    ids_to_delete = list(index.list(prefix=payload.documentId, namespace=payload.userId))

    if not ids_to_delete:
        raise HTTPException(status_code=404, detail="KhÃ´ng tÃ¬m tháº¥y vectors nÃ o vá»›i documentId nÃ y.")

    # BÆ°á»›c 2: XoÃ¡ vector theo ID
    index.delete(
        namespace=payload.userId,
        ids=ids_to_delete
    )

    return {"deleted_ids": ids_to_delete}

@app.post("/v1/chat/completions")
def create_chat_completion(payload: ChatCompletionPayload):
    try:
        # Convert Pydantic Message models to dictionaries if payload.messages contains them
        messages_for_api = [message.model_dump() for message in payload.messages]

        chat_completion = client.chat.completions.create(
            messages=messages_for_api,
            model=payload.model or "deepseek-r1-distill-llama-70b"  # Use model from payload or default
            # You can pass other parameters from payload to the API call if needed
            # e.g., temperature=payload.temperature
        )
        return chat_completion.model_dump()
    except Exception as e:
        print(f"Error during chat completion: {e}") # For server-side logging
        raise HTTPException(status_code=500, detail=str(e))
